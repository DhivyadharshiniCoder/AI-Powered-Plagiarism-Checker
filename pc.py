# -*- coding: utf-8 -*-
"""pc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PG6c4n_LZhWZjM_H7iJhJqnHk1QdT6Kh
"""

#!pip install sentence-transformers nltk python-docx PyPDF2

from sentence_transformers import SentenceTransformer, util
import re

# Load the Sentence-BERT model
model = SentenceTransformer('paraphrase-MiniLM-L6-v2')

def get_sentences(text):
    # Split text into sentences using punctuation
    sentences = re.split(r'(?<=[.!?]) +', text.strip())
    return [s.strip() for s in sentences if s.strip()]

def compute_similarity(text1, text2, threshold=0.75):
    sent1 = get_sentences(text1)
    sent2 = get_sentences(text2)

    emb1 = model.encode(sent1, convert_to_tensor=True)
    emb2 = model.encode(sent2, convert_to_tensor=True)

    cosine_scores = util.pytorch_cos_sim(emb1, emb2)

    matches = []
    for i in range(len(sent1)):
        for j in range(len(sent2)):
            score = cosine_scores[i][j].item()
            if score >= threshold:
                matches.append((sent1[i], sent2[j], score))

    return matches

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

with open("file1.txt", "r", encoding="utf-8") as f:
    text1 = f.read()

with open("file2.txt", "r", encoding="utf-8") as f:
    text2 = f.read()

matches = compute_similarity(text1, text2, threshold=0.6)

if matches:
    print(f"ğŸ” Found {len(matches)} matching sentence pairs:\n")
    for i, (a, b, score) in enumerate(matches, 1):
        print(f"ğŸ”¹ Match {i}:")
        print(f"Text 1: {a}")
        print(f"Text 2: {b}")
        print(f"ğŸ§  Similarity Score: {round(score, 2)}\n{'-'*60}")
else:
    print("âœ… No significant plagiarism detected.")

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Display plots inline
# %matplotlib inline

import pandas as pd

df = pd.DataFrame(matches, columns=["Sentence_File1", "Sentence_File2", "Similarity_Score"])
df.to_csv("similarity_output.csv", index=False)
df.head()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the generated CSV
df = pd.read_csv("similarity_output.csv")

# Basic Summary
print(df.describe())

# Plot distribution of similarity scores
sns.histplot(df['Similarity_Score'], bins=10, kde=True, color='skyblue')
plt.title("Distribution of Sentence Similarity Scores")
plt.xlabel("Similarity Score")
plt.ylabel("Frequency")
plt.show()

# Add Plagiarism Label based on threshold
df['Plagiarised'] = df['Similarity_Score'] >= 0.6

# Count Plot
sns.countplot(x='Plagiarised', data=df)
plt.title("Count of Plagiarised vs Non-Plagiarised Sentences")
plt.xlabel("Plagiarised?")
plt.ylabel("Number of Matches")
plt.show()

total_matches = len(df)
plagiarised_matches = df['Plagiarised'].sum()
percentage = (plagiarised_matches / total_matches) * 100

print(f"ğŸ”¢ Plagiarised Matches: {plagiarised_matches}/{total_matches}")
print(f"ğŸ“Š Percentage Plagiarised: {percentage:.2f}%")

import pandas as pd

df = pd.read_csv("similarity_output_task3.csv")
print(df['Plagiarised'].value_counts())  # Should show both 1 and 0

from sklearn.model_selection import train_test_split

X = df[['Similarity_Score']]
y = df['Plagiarised']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

from sklearn.metrics import accuracy_score, f1_score

print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))

X = df.drop(columns=["Plagiarised"])
y = df["Plagiarised"]

# âœ… Use only Similarity_Score as feature
X = df[["Similarity_Score"]]
y = df["Plagiarised"]

# Train/test split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# âœ… Predict probabilities
y_prob = model.predict_proba(X_test)[:, 1]

X = df[["Similarity_Score"]]

# ğŸ“Œ Step 1: Import Required Libraries
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    confusion_matrix, classification_report,
    accuracy_score, f1_score, roc_curve, roc_auc_score
)

# ğŸ“Œ Step 2: Load Dataset
df = pd.read_csv("similarity_output_task3.csv")

# ğŸ“Œ Step 3: Feature and Label Selection
X = df[["Similarity_Score"]]
y = df["Plagiarised"]

# ğŸ“Œ Step 4: Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ğŸ“Œ Step 5: Train Logistic Regression Model
model = LogisticRegression()
model.fit(X_train, y_train)

# ğŸ“Œ Step 6: Make Predictions
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

# ğŸ“Œ Step 7: Evaluate the Model
print("ğŸ”¹ Accuracy:", accuracy_score(y_test, y_pred))
print("ğŸ”¹ F1 Score:", f1_score(y_test, y_pred))
print("ğŸ”¹ Classification Report:\n", classification_report(y_test, y_pred))
print("ğŸ”¹ Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# ğŸ“Œ Step 8: ROC Curve & AUC Score
auc = roc_auc_score(y_test, y_prob)
print(f"ğŸ”µ ROC-AUC Score: {round(auc, 2)}")

fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.figure(figsize=(6, 5))
plt.plot(fpr, tpr, label=f"ROC Curve (AUC = {round(auc, 2)})", color='blue')
plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ğŸ“ˆ ROC Curve â€“ Plagiarism Classifier")
plt.legend()
plt.grid(True)
plt.show()

# ğŸ“Œ Step 1: Import Required Libraries
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix

# ğŸ“Œ Step 2: Load Your Data
df = pd.read_csv("similarity_output_task3.csv")

# ğŸ“Œ Step 3: Prepare Features and Labels
X = df[["Similarity_Score"]]
y = df["Plagiarised"]

# ğŸ“Œ Step 4: Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ğŸ“Œ Step 5: Decision Tree Model
dt_model = DecisionTreeClassifier(max_depth=3, random_state=42)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)

print("ğŸŒ³ Decision Tree Accuracy:", accuracy_score(y_test, y_pred_dt))
print("ğŸŒ³ F1 Score:", f1_score(y_test, y_pred_dt))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))
print(classification_report(y_test, y_pred_dt))

# ğŸ“Œ Visualize Decision Tree
plt.figure(figsize=(12, 6))
plot_tree(dt_model, feature_names=["Similarity_Score"], class_names=["Original", "Plagiarised"], filled=True)
plt.title("Decision Tree Visualization")
plt.show()

# ğŸ“Œ Step 6: Random Forest Model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

print("ğŸŒ² Random Forest Accuracy:", accuracy_score(y_test, y_pred_rf))
print("ğŸŒ² F1 Score:", f1_score(y_test, y_pred_rf))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))
print(classification_report(y_test, y_pred_rf))

# ğŸ“Œ Feature Importance (Only 1 feature here)
importance = rf_model.feature_importances_[0]
print(f"ğŸ“Š Feature Importance of 'Similarity_Score': {round(importance, 4)}")

# ğŸ“Œ Step 1: Import Required Libraries
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# ğŸ“Œ Step 2: Load Dataset
df = pd.read_csv("similarity_output_task3.csv")  # Make sure this file exists

# ğŸ“Œ Step 3: Prepare Feature and Label
X = df[["Similarity_Score"]]
y = df["Plagiarised"]

# ğŸ“Œ Step 4: Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# ğŸ“Œ Step 5: KNN Classifier (K=3)
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)

# ğŸ“Œ Step 6: Evaluate the Model
print("âœ… Accuracy:", accuracy_score(y_test, y_pred))
print("ğŸ“Š Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("ğŸ“‘ Classification Report:\n", classification_report(y_test, y_pred))

# ğŸ“Œ Step 7: Accuracy vs K Plot
k_values = list(range(1, 11))
accuracies = []

for k in k_values:
    knn_k = KNeighborsClassifier(n_neighbors=k)
    knn_k.fit(X_train, y_train)
    pred_k = knn_k.predict(X_test)
    acc_k = accuracy_score(y_test, pred_k)
    accuracies.append(acc_k)

plt.figure(figsize=(8, 4))
plt.plot(k_values, accuracies, marker='o')
plt.title("KNN Accuracy for Different K Values")
plt.xlabel("K")
plt.ylabel("Accuracy")
plt.grid(True)
plt.show()

# Step 1: Import Libraries
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Step 2: Load Dataset
df = pd.read_csv("similarity_output_task3.csv")

# Step 3: Features and Labels
X = df[["Similarity_Score"]]  # only feature
y = df["Plagiarised"]         # label

# Step 4: Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# Step 5: Train SVM with Linear Kernel
linear_svm = SVC(kernel="linear", C=1.0)
linear_svm.fit(X_train, y_train)
y_pred_linear = linear_svm.predict(X_test)

# Step 6: Train SVM with RBF Kernel
rbf_svm = SVC(kernel="rbf", C=1.0, gamma="scale")
rbf_svm.fit(X_train, y_train)
y_pred_rbf = rbf_svm.predict(X_test)

# Step 7: Evaluation Function
def evaluate(y_true, y_pred, kernel_type):
    print(f"\nğŸ¯ SVM Evaluation: {kernel_type} Kernel")
    print("Accuracy:", accuracy_score(y_true, y_pred))
    print("Classification Report:\n", classification_report(y_true, y_pred))
    sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt="d", cmap="Blues")
    plt.title(f"{kernel_type} Kernel - Confusion Matrix")
    plt.show()

evaluate(y_test, y_pred_linear, "Linear")
evaluate(y_test, y_pred_rbf, "RBF")

# ğŸ“Œ Step 1: Import Required Libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import confusion_matrix, silhouette_score

# ğŸ“Œ Step 2: Load your dataset
df = pd.read_csv("similarity_output_task3.csv")

# ğŸ“Œ Step 3: Feature Selection and Scaling
X = df[["Similarity_Score"]]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# ğŸ“Œ Step 4: Apply KMeans Clustering (2 clusters: plagiarised vs not)
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
df["Cluster"] = kmeans.fit_predict(X_scaled)

# ğŸ“Œ Step 5: Visualize the Clusters
plt.figure(figsize=(8, 5))
sns.scatterplot(data=df, x="Similarity_Score", y=[0]*len(df), hue="Cluster", palette="Set2", s=100)
plt.title("ğŸ” K-Means Clustering on Similarity Scores")
plt.xlabel("Similarity Score")
plt.yticks([])
plt.grid(True)
plt.show()

# ğŸ“Œ Step 6: Silhouette Score (optional evaluation metric)
score = silhouette_score(X_scaled, df["Cluster"])
print("ğŸ§  Silhouette Score:", round(score, 3))

# ğŸ“Œ Step 7: Optional â€“ Compare with Ground Truth
if "Plagiarised" in df.columns:
    print("\nâœ… Confusion Matrix (Cluster vs. Actual Label):")
    print(confusion_matrix(df["Plagiarised"], df["Cluster"]))

# ğŸ“Œ Step 1: Import Required Libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt

# ğŸ“Œ Step 2: Load Your Data
df = pd.read_csv("similarity_output_task3.csv")

# ğŸ“Œ Step 3: Feature and Target Selection
X = df[["Similarity_Score"]]
y = df["Plagiarised"]

# ğŸ“Œ Step 4: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ“Œ Step 5: Train Decision Tree Classifier
tree_model = DecisionTreeClassifier(random_state=42)
tree_model.fit(X_train, y_train)

# ğŸ“Œ Step 6: Predictions
y_pred = tree_model.predict(X_test)

# ğŸ“Œ Step 7: Evaluation
print("âœ… Accuracy:", round(accuracy_score(y_test, y_pred) * 100, 2), "%\n")
print("ğŸ§¾ Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nğŸ“Š Classification Report:\n", classification_report(y_test, y_pred))

# ğŸ“Œ Step 8: Visualize the Decision Tree
plt.figure(figsize=(10, 6))
plot_tree(tree_model, feature_names=["Similarity_Score"], class_names=["Original", "Plagiarised"], filled=True)
plt.title("ğŸ§  Decision Tree for Plagiarism Detection")
plt.show()

# ğŸ“Œ Step 1: Import Required Libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# ğŸ“Œ Step 2: Load Dataset
df = pd.read_csv("similarity_output_task3.csv")

# ğŸ“Œ Step 3: Select Feature and Target
X = df[["Similarity_Score"]]
y = df["Plagiarised"]

# ğŸ“Œ Step 4: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ğŸ“Œ Step 5: Train Random Forest Model
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# ğŸ“Œ Step 6: Make Predictions
y_pred = rf_model.predict(X_test)

# ğŸ“Œ Step 7: Evaluate the Model
print("âœ… Accuracy:", round(accuracy_score(y_test, y_pred) * 100, 2), "%\n")
print("ğŸ§¾ Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nğŸ“Š Classification Report:\n", classification_report(y_test, y_pred))

# ğŸ“Œ Step 8: (Optional) Visualize Feature Importance
importances = rf_model.feature_importances_
plt.figure(figsize=(6,4))
sns.barplot(x=importances, y=["Similarity_Score"])
plt.title("ğŸ“Š Feature Importance - Random Forest")
plt.show()